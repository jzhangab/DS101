{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Statistics with Python\n",
    "\n",
    "1. Simple distribution plots\n",
    "2. Confidence intervals\n",
    "3. Hypothesis testing\n",
    "4. Simple linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages that you need\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris data-set from sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                  columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph boxplot distributions for the dataframe columns\n",
    "%matplotlib inline\n",
    "df.plot.box(figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph a scatterplot matrix to visualize distribution and interaction of each column/component \n",
    "%matplotlib inline\n",
    "pd.plotting.scatter_matrix(df, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need some more packages\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
    "# Confidence interval calculated by scipy\n",
    "\n",
    "# Let's calculated confidence interval of \"sepal width (cm)\" at 95%\n",
    "mean_sw = df['sepal width (cm)'].mean()\n",
    "std_sw = df['sepal width (cm)'].std()\n",
    "\n",
    "# Store confidence interval in the variable ci\n",
    "ci = scipy.stats.norm.interval(0.95,\n",
    "                               loc=mean_sw,\n",
    "                               scale=std_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean sepal width (cm): \", mean_sw)\n",
    "print (\"Standard deviation sepal width (cm): \", std_sw)\n",
    "print (\"UL, LL 95% confidence bounds: \", ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the confidence interval\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(df['sepal width (cm)'], bins=10)\n",
    "\n",
    "# Plot confidence interval lines as red lines\n",
    "plt.axvline(x=ci[0], \n",
    "            ymin=0, \n",
    "            ymax=max(df['sepal width (cm)']), \n",
    "            color='red')\n",
    "\n",
    "plt.axvline(x=ci[1], \n",
    "            ymin=0, \n",
    "            ymax=max(df['sepal width (cm)']), \n",
    "            color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hypothesis Testing\n",
    "\n",
    "The \"target\" column actually represents 3 different types of iris. In this section we will perform hypothesis testing to compare the different targets based on the factors such as sepal width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Null Hypothesis: There is no difference in mean petal length (cm) between target levels 0.0 and 1.0\n",
    "\n",
    "We will compare the column values for petal length (cm) between the target levels 0.0 and 1.0. We will first need to get each data set in the form of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for mean petal length (cm) for target level 0.0\n",
    "petallength_0 = df.loc[df['target'] == 0.0]['petal length (cm)'].values\n",
    "\n",
    "# Dataset for mean petal length (cm) for target level 1.0\n",
    "petallength_1 = df.loc[df['target'] == 1.0]['petal length (cm)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welch's t-test for unequal variances\n",
    "t, p = scipy.stats.ttest_ind(petallength_0, petallength_1, equal_var=False)\n",
    "\n",
    "print (\"t-value: \", t)\n",
    "print (\"p-value: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have more than 2 groups to compare, we can use ANOVA to calculate the F-statistic. A significant F-stat indicates that the difference between targets (0, 1, and 2) can be explained by the category of data we are using (petal length (cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for mean petal length (cm) for target level 0.0\n",
    "petallength_0 = df.loc[df['target'] == 0.0]['petal length (cm)'].values\n",
    "\n",
    "# Dataset for mean petal length (cm) for target level 1.0\n",
    "petallength_1 = df.loc[df['target'] == 1.0]['petal length (cm)'].values\n",
    "\n",
    "# Dataset for mean petal length (cm) for target level 2.0\n",
    "petallength_2 = df.loc[df['target'] == 2.0]['petal length (cm)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, p = scipy.stats.f_oneway(petallength_0, petallength_1, petallength_2)\n",
    "\n",
    "print (\"f-stat: \", f)\n",
    "print (\"p-value: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Models\n",
    "\n",
    "Least squares regression hypothesizes a linear model for the parameters in a dataset and provides an estimation of coefficient for each parameter and whether or not it is significant as a predictor. This is a great way to tell if a particular parameter is significant for the dataset. We can analyze all columns of parameters at once instead of grinding through f-stats for each manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear model\n",
    "model = sm.OLS(endog = df['target'],\n",
    "               exog = df[[c for c in list(df) if c != 'target']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
